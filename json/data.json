[
  {
    "id": 0,
    "projectType": "star",
    "title": "Red Cross",
    "promoText": "An web application that allows caregivers to provide aid to eventgoers.",
    "promoImage": "redCross",
    "image": ["redCross"],
    "video": "https://www.youtube.com/embed/j-PcZz788oc?si=bReNc8rZk7NaLphc",
    "promoAlt": "Red Cross for caregivers and event visitors.",
    "codeLink": "https://github.com/sarabluekens/Milan-Sara",
    "question": "For full-stack development, we (groups of two) were assigned to create a web app that controls a full flow for a certain subject. We chose to work for the Red Cross. More specifically, Red Cross on events. Milan created the platform for companies organizing events and needing first aid and the Inventory and caregivers assignment. I created the platform for the caregivers and the visitors of the event.",
    "solution": "Our responsive solution can be divided into four big parts. First, the companies apply for first-aid support. Second, when the Red Cross creates the event and adds materials and people to it. The third part is where visitors report an accident. The last part is where the caregivers can see the alert and be guided to the victim. Since I created the third and fourth steps, I will be focusing on those. Visitors to the event can scan a QR code or surf to www.redcross.be. Once on the site, they select the event they attend and, after that, what type of emergency they have. As soon as that is selected, the case is created. The caregivers that are assigne the event of the emergency on the same day as the emergency will get an alert for a new case. When selecting this case, they see the victim on the map and the victim will see the caregiver on the map. The coordinates update live every time one changes. When the caregiver and the victim are close enough, they are redirected to the next step. For the victim, that's a flash screen to get the attention of the searching caregiver. For the caregiver, that's an after-action report, since no digital aid is needed in providing the physical aid. After the report is filled out, the case is closed.",
    "role": "I developed (frontend, backend, and testing) and designed the full caregivers and visitors part.",
    "gamePlay": "A visitor selects the event and emergency they have. A caregiver assigned to the event gets an alert of a new case and can see the victim on the map. The app guides them to each other, so proper aid can be provided. After the aid is provided, an after-action report, with follow-up if needed, is filled in for the inventory of the supplies and insurance companies.",
    "aftermath": "This project has a full frontend, and backend and is linked by data to the other teammates' part. For example, when filling in the after-action report of a case, only the materials selected for that event and still in inventory will be available. Another example is the events and caregivers available for an event are the ones assigned for that event on that workday. We did this to make the project as realistic as possible, which complicated certain bits quite a bit. In hindsight, we should've made the project a bit more simple. But we are very proud of the result.",

    "tags": [
      "Design",
      "Vue.js",
      "Typescript",
      "TailwindCSS",
      "Google Maps",
      "GeoLocation",
      "TypeOrm",
      "GraphQl",
      "MongoDB",
      "PWA"
    ],
    "roleTags": ["Frontend", "Backend", "Design"]
  },
  {
    "id": 1,
    "projectType": "career",
    "title": "Jumping Jaws",
    "promoText": "An endless runner game where two players need to jump on a trampoline to survive.",
    "promoImage": "trampolineGame",
    "image": ["trampolineGame"],
    "video": "https://www.youtube.com/embed/0VSpQeysMvU?si=Fzd_NK5q3raHbNHy",
    "promoAlt": "Jumping Jaws op de Facts Expo in Gent",
    "codeLink": "https://github.com/DauweQuinten/Trampoline_Groep2_FrontEnd",
    "question": "This project was created for Sports innovation campus in Bruges. They asked us to create a digital application to encourage the youth to exercise more.  We were given trampolines by the client. ",
    "solution": "In our solution we created an endless runner game that can be controlled by jumping on the trampoline. The game was created in Unity. The design was made in Figma. The backend existed of an Xbox Kinect where the jumps were detected and registrated with node.Js. The backend data was sent to the frontend through a websocket.",
    "role": "I worked on this project with three other classmates. My role in this project was Ux/Ui Research, Design and  the frontend development of the game (in association with a frontend partner). The others worked on research, Ui implementation, communication with backend and the backend itself. ",
    "gamePlay": "The game is a endless runner game where two players have to work together to steer a boat through a river full of obstacles. Every time the boat hits an obstacle it gets slowed down for a second. There is also a shark chasing them and as soon as he catches up with the boat the game ends. The goal of the game is to stay ahead of the shark for as long as possible.",
    "aftermath": "In our demo and expo, where we set up the game for the public, we noticed that the setup often was a bit difficult to understand. Especially the calibration of the Players proved a very difficult part of the game. Once the people started playing the game itself, we found that they really liked it. They often played more then once to improve their high score. Even though the game was designed for the youth we found that adults liked it a lot as-well, which was really satisfying for us to see. ",

    "tags": [
      "Unity",
      "C#",
      "UX/UI",
      "Design",
      "Websocket",
      "Xbox Kinect",
      "ESP"
    ],
    "roleTags": ["Frontend", "Research", "UX/UI", "Design"]
  },
  {
    "id": 2,
    "projectType": "career",
    "title": "To the grave",
    "promoText": "A horrifying quiz that determines how you will meet your end.",
    "promoImage": "toTheGrave",
    "image": ["toTheGrave"],

    "promoAlt": "An online calculator of Death.",
    "codeLink": "https://github.com/sarabluekens/calculator",
    "externalLink": "https://bucolic-bombolone-d6b837.netlify.app/",
    "question": "For a school project we were asked to build some sort of calculator. Where the input of the user, changed the outcome of the calculator.",
    "solution": "I created a calculator that reveals how the user will meet their end, depending on their input. To lighten the mood a bit on this dark theme, I put some humor in it. And of course there is a little easter egg for my former teachers (hint: their names were “Benoit” and “Simon”). I created this app in React.  I worked with Components en Modules CSS. This site is hosted on Netlify.",
    "role": "Since this was an inbetween assignment, I made this project by myself. I worked on Concept, UX, Design and Development. ",
    "gamePlay": "Visitors enter the website on the homescreen. There they can choose between the calculator and a list of all the possible answers. If they go to the calculator they can fill in the questions and the answer will appear based on what people fill in. This all happens in live reload. No redirecting to other pages is required. ",
    "aftermath": "This project has no intention of being used after the end of the assignment. The projects purpose was to practice the core concepts of React and get used to the best practices. This project helped me improve my React knowledge and usage for later projects. ",
    "tags": ["React", "Javascript", "HTML/CSS", "Netlify"],
    "roleTags": ["Frontend", "Design"]
  },
  {
    "id": 3,
    "projectType": "career",
    "title": "Led Lightroom",
    "promoText": "An interactive lightroom where people change the lights by moving their body in the room.",
    "promoImage": "smileSafari",
    "image": ["smileSafari"],
    "promoAlt": "3D of the lightroom with the light effects.",
    "externalLink": "https://www.behance.net/gallery/150697827/Sunset-Room-An-immersive-lightroom-for-Smile-Safari?tracking_source=search_projects%7Csmile+safari",
    "question": "For my bachelor thesis I worked with two other classmates on a project for Smile Safari. They asked us to create an interactive digital room, where people could take lots of pictures for social media. Most important for our client was that it was interactive and resulted in great pictures.",
    "solution": "We created an emersive lightroom with ledstrips and Arduino Uno board. These ledstrips were hung on the wall to guide the visitors into the room. We also used a Led matrix in combination with an arduino board to create our big led background, which was curved to avoid sharp corners on the photo. Lastly we used a Kinect Azure with Touchdesigner software to transfer real life feed to a led matrix giving control to the visiters",
    "role": "My role in this project was as wel Research the target audience as well as the best UX for the room. Aside from my research role I was also the lead creative developer working with all the Arduino and led strips/matrix and Touchdesigner software. ",
    "gamePlay": "The room is designed to give every visitor a unique and social media worthy experience. Visitors would enter the room seeing a dark hallway. When they move the led strips they pass would flash on creating a tunnel of light that follows them. Once they reach the end of the room a Kinect will detect the visitors and register their movements. TouchDesigner will then transfer the movements to a led matrix, creating a magical interactive background. ",
    "aftermath": "For our bachelor thesis we made a prototype, maquette and 3D render of the room. The owner of Smile Safari also came to our final presentation. After the presentation Smile Safari contacted us for more information and the specific schemes of our installation. We were told they plan on building the room in one of their musea. Until this day we still excitedly await notification that our room has actually been build for real.",
    "tags": [
      "Arduino",
      "TouchDesigner",
      "LedMatrix/Strip",
      "Javascript",
      "Xbox Kinect"
    ],
    "roleTags": ["Research", "UX/UI", "Creative Development"]
  },

  {
    "id": 4,
    "projectType": "career",
    "title": "A Write for sore eyes",
    "promoText": "A web application that allows you to write out what you’re feeling. The website adjusts according to your mood.",
    "promoImage": "schrijfHetUit",
    "image": ["schrijfHetUit"],

    "promoAlt": "Homescreen of the website.",
    "codeLink": "https://github.com/sarabluekens/personal",
    "externalLink": "https://sleepy-jones-731a03.netlify.app/",
    "question": "We were asked to create a desktop React project, where the input of the user had influence on the output that another user would receive. It did not require a responsive solution. ",
    "solution": "In my solution I created an app where visitors can write out their emotions. They simplty select an emotion and start writing whatever needs to get off their chest. After they press the button the link of the letter is generated and shown. Important detail: the emotion they choose when writing the letter decides the design of the letter that gets send. ",
    "role": "Since this was an inbetween assignment, I made this project by myself. I worked on Concept, UX, Design and Development. ",
    "gamePlay": "Visitors come to the website to write out their worries. There is no obligation to share what they write with anybody. This app is meant to let people get what bothers them off their chest. If however, people decide to share the letter with someone else; they can send the link, that is automatically generated and shown with the person to read it. The letter that the other person receives is designed according to the emotion of the author. ",
    "aftermath": "This project has no intention of being used after the end of the assignment. The projects purpose was to practice the core concepts of React and get used to the best practices. This project helped me improve my React knowledge and usage for later projects. ",
    "tags": ["React", "Next.js", "Netlify", "Design"],
    "roleTags": ["Frontend", "Research", "Design"]
  },
  {
    "id": 5,
    "projectType": "hobby",
    "title": "Sneaky Sam",
    "promoText": "An endless runner game that is controlled with the movement of the player's head.",
    "promoImage": "sneakySam",
    "image": ["sneakySam"],

    "promoAlt": "Startscreen of the game in Unity.",
    "codeLink": "https://github.com/sarabluekens/PassionProjectHerex",
    "externalLink": "https://www.sarabluekens.be/passion/sam2/",
    "experiment": "Sneaky sam is a project where i experimented with Machine Learning and a game development platform. Some sort of live feed was required for this experiment.",
    "result": "I made an endless runner game in Unity. The player has to control the character by moving his head in front of the webcam of the laptop. The webcam input is processed by Tensorflow. Tensorflow tracks the position of the head (in this case the left eye) and uses this data to steer the character between lanes. The character kan also jump by moving upwards with the head",
    "aftermath": "It is a fun and simple game. There are still a few bugs in there, but it was very interesting to see how Tensorflow en Unity work. And especially how you can combine these together to transform output from Tensorflow to input for Unity.  I will definitely use this in future projects. I had a blast.",
    "tags": ["Unity", "C#", "UX/UI", "Sound", "Javascript", "TensorFlow"]
  },
  {
    "id": 6,
    "projectType": "hobby",
    "title": "3D Print",
    "promoText": "A keychain I 3D modelled and printed myself.",
    "promoImage": "print",
    "image": ["print"],

    "promoAlt": "Startscreen of the game in Unity.",
    "experiment": "I was able to experiment with a 3D printer.  Decided to make a keychain.  But instead of just printing a rectangle I wanted to do something special",
    "result": "I created (3D modelled) a cat. This was made using the 3D printers software.  It has been a while because of which I don’t really remember the name of the software. I used an Image as reference and then sculpted a flat 3D model of a cat. ",
    "aftermath": "The 3D modelling is a lot of work and very time consuming, but the 3D print totally makes it worth its time. While I had a fair share of frustrations during the modelling, I enjoyed the overall process. The satisfying result of having your 3D model makes it all so much more fun. In the end my keychain was not really a keychain anymore, but that’s oke. I learned a lot, which was the goal after all.",
    "tags": ["3D print"]
  },
  {
    "id": 7,
    "projectType": "career",
    "title": "Endless runner game in AI/AR",
    "promoText": "An endless runner game in combination with AI and AR to give the player a more immersive experience.",
    "promoImage": "research",
    "image": ["research"],
    "video": "https://www.youtube.com/embed/wLq4bcJCM6U?si=pRNO-2Wf-k3fosMD",
    "promoAlt": "Startscreen of the game in Flutter.",
    "solution": "I created a game in Flutter with the Flame engine. There are two ways to play the game. In the first way the player chooses/creates their own obstacles with the Dall-E image generator. The second way really immerses the player in the game with AR. By using the AR_Flutter_plugin the game transforms in a first person view. To get the objects to hit the player I had to work around the anchor point of an AR environment. I repositioned the obstacle over time closer to the players cöordinates, making it move. By physically moving the phone the player can dodge the obstacles. ",
    "aftermath": "Very proud of the results. I had a hard time finding a workaround for the AR anchor points to get the obstacles to move. Once I found the workaround the results became very satisfying. The AI part of the project learned me that AI is not gonna take over the world anytime soon (Phew). More specifically when asking for a specific amount, it rarely provides the right amount. For example when I asked for 5 frames in a spritesheet, it sometimes generated 2 or 12 or even 120! I was able to solve this by letting the player double checking the amount before creating the game. I learned so much from this project in terms of being stuck and finding creative solutions. ",
    "tags": ["research", "AI", "AR", "Flutter", "Flame", "Dall-E"],
    "codeLink": "https://github.com/sarabluekens/researchProject",
    "question": "In a 3weeks span I researched the possibilities of combining AI and AR with an endless runner game. I wanted to see if it was possible to create a more immersive experience for the player.",
    "role": "I did this project on my own so I was responible for Concept, research, design and development. ",
    "roleTags": ["Frontend", "Research", "UX/UI", "Design"]
  }
]
